{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool for Wikipedia API\n",
    "\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
    "tool_wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool for Arxiv API\n",
    "\n",
    "from langchain.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import  ArxivAPIWrapper\n",
    "\n",
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
    "tool_arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidd/miniconda3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Custom Tool for langchain docs\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "loader = WebBaseLoader(web_path='https://python.langchain.com/v0.2/docs/concepts/')\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = splitter.split_documents(docs)\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "db = FAISS.from_documents(documents, embeddings)\n",
    "retirver = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"You can therefore do:# Initialize a toolkittoolkit = ExampleTookit(...)# Get list of toolstools = toolkit.get_tools()Agents\\u200bBy themselves, language models can't take actions - they just output text.\\nA big use case for LangChain is creating agents.\\nAgents are systems that use an LLM as a reasoning enginer to determine which actions to take and what the inputs to those actions should be.\\nThe results of those actions can then be fed back into the agent and it determine whether more actions are needed, or whether it is okay to finish.LangGraph is an extension of LangChain specifically aimed at creating highly controllable and customizable agents.\\nPlease check out that documentation for a more in depth overview of agent concepts.There is a legacy agent concept in LangChain that we are moving towards deprecating: AgentExecutor.\\nAgentExecutor was essentially a runtime for agents.\", metadata={'source': 'https://python.langchain.com/v0.2/docs/concepts/', 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'description': 'This section contains introductions to key parts of LangChain.', 'language': 'en'}),\n",
       " Document(page_content='AgentExecutor was essentially a runtime for agents.\\nIt was a great place to get started, however, it was not flexible enough as you started to have more customized agents.\\nIn order to solve that we built LangGraph to be this flexible, highly-controllable runtime.If you are still using AgentExecutor, do not fear: we still have a guide on how to use AgentExecutor.\\nIt is recommended, however, that you start to transition to LangGraph.', metadata={'source': 'https://python.langchain.com/v0.2/docs/concepts/', 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'description': 'This section contains introductions to key parts of LangChain.', 'language': 'en'}),\n",
       " Document(page_content='which will be responsible for calling the appropriate method on each \"registered\" callback handler when the event is triggered.Passing callbacks\\u200bThe callbacks property is available on most objects throughout the API (Models, Tools, Agents, etc.) in two different places:The callbacks are available on most objects throughout the API (Models, Tools, Agents, etc.) in two different places:Request time callbacks: Passed at the time of the request in addition to the input data.', metadata={'source': 'https://python.langchain.com/v0.2/docs/concepts/', 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'description': 'This section contains introductions to key parts of LangChain.', 'language': 'en'}),\n",
       " Document(page_content=\"It is more general than a vector store.\\nA retriever does not need to be able to store documents, only to return (or retrieve) them.\\nRetrievers can be created from vectorstores, but are also broad enough to include Wikipedia search and Amazon Kendra.Retrievers accept a string query as input and return a list of Document's as output.Tools\\u200bTools are interfaces that an agent, a chain, or a chat model / LLM can use to interact with the world.A tool consists of the following components:The name of the toolA description of what the tool doesJSON schema of what the inputs to the tool areThe function to callWhether the result of a tool should be returned directly to the user (only relevant for agents)The name, description and JSON schema are provided as context\\nto the LLM, allowing the LLM to determine how to use the tool\\nappropriately.Given a list of available tools and a prompt, an LLM can request\", metadata={'source': 'https://python.langchain.com/v0.2/docs/concepts/', 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'description': 'This section contains introductions to key parts of LangChain.', 'language': 'en'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retirver.invoke(\"agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriver_tool = create_retriever_tool(retirver, \"Langchain\", \"Search for concepts in the Langchain documentation. For any questions about Langchain, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriver_tool, tool_wiki, tool_arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Executer\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Langchain` with `{'query': 'What are agents in Langchain?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mYou can therefore do:# Initialize a toolkittoolkit = ExampleTookit(...)# Get list of toolstools = toolkit.get_tools()Agents​By themselves, language models can't take actions - they just output text.\n",
      "A big use case for LangChain is creating agents.\n",
      "Agents are systems that use an LLM as a reasoning enginer to determine which actions to take and what the inputs to those actions should be.\n",
      "The results of those actions can then be fed back into the agent and it determine whether more actions are needed, or whether it is okay to finish.LangGraph is an extension of LangChain specifically aimed at creating highly controllable and customizable agents.\n",
      "Please check out that documentation for a more in depth overview of agent concepts.There is a legacy agent concept in LangChain that we are moving towards deprecating: AgentExecutor.\n",
      "AgentExecutor was essentially a runtime for agents.\n",
      "\n",
      "AgentExecutor was essentially a runtime for agents.\n",
      "It was a great place to get started, however, it was not flexible enough as you started to have more customized agents.\n",
      "In order to solve that we built LangGraph to be this flexible, highly-controllable runtime.If you are still using AgentExecutor, do not fear: we still have a guide on how to use AgentExecutor.\n",
      "It is recommended, however, that you start to transition to LangGraph.\n",
      "\n",
      "Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling.\n",
      "Please see the tool calling section for more information.LLMs​Language models that takes a string as input and returns a string.\n",
      "These are traditionally older models (newer models generally are ChatModels, see below).Although the underlying models are string in, string out, the LangChain wrappers also allow these models to take messages as input.\n",
      "This makes them interchangeable with ChatModels.\n",
      "When messages are passed in as input, they will be formatted into a string under the hood before being passed to the underlying model.LangChain does not provide any LLMs, rather we rely on third party integrations.Messages​Some language models take a list of messages as input and return a message.\n",
      "There are a few different types of messages.\n",
      "All messages have a role, content, and response_metadata property.The role describes WHO is saying the message.\n",
      "\n",
      "to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to use a model to call toolsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to add a human-in-the-loop for toolsHow to create and query vector storesConceptual guideEcosystem🦜🛠️ LangSmith🦜🕸️ LangGraph🦜️🏓 LangServeVersionsOverviewRelease PolicyPackagesv0.2LangChain v0.2astream_events v2ChangesSecurityConceptual guideOn this pageConceptual guideThis section contains introductions to key parts of LangChain.Architecture​LangChain as a framework consists of a number of packages.langchain-core​This package contains base abstractions of different components and ways to compose them together.\u001b[0m\u001b[32;1m\u001b[1;3mLangchain Agents are systems that use LLMs (Large Language Models) for reasoning and decision-making to determine which actions to take based on user inputs. They use these LLMs to figure out what actions to take and what inputs to use for those actions. The results of these actions can then be fed back into the agent to decide if further actions are needed or if the task is complete. \n",
      "\n",
      "Let me know if you'd like to explore a specific aspect of Langchain Agents or have any other questions. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what are agents in Langchain?',\n",
       " 'output': \"Langchain Agents are systems that use LLMs (Large Language Models) for reasoning and decision-making to determine which actions to take based on user inputs. They use these LLMs to figure out what actions to take and what inputs to use for those actions. The results of these actions can then be fed back into the agent to decide if further actions are needed or if the task is complete. \\n\\nLet me know if you'd like to explore a specific aspect of Langchain Agents or have any other questions. \\n\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what are agents in Langchain?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
